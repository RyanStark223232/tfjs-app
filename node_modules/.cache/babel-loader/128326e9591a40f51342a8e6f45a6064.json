{"ast":null,"code":"import _slicedToArray from \"C:/Users/wongh/Documents/GitHub/tfjs-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { BatchMatMul } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\r\n * Computes the dot product of two matrices, A * B. These must be matrices.\r\n *\r\n * ```js\r\n * const a = tf.tensor2d([1, 2], [1, 2]);\r\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\r\n *\r\n * a.matMul(b).print();  // or tf.matMul(a, b)\r\n * ```\r\n * @param a First matrix in dot product operation.\r\n * @param b Second matrix in dot product operation.\r\n * @param transposeA If true, `a` is transposed before multiplication.\r\n * @param transposeB If true, `b` is transposed before multiplication.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Matrices'}\r\n */\n\nfunction matMul_(a, b) {\n  var transposeA = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  var transposeB = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  var $a = convertToTensor(a, 'a', 'matMul');\n  var $b = convertToTensor(b, 'b', 'matMul');\n\n  var _makeTypesMatch = makeTypesMatch($a, $b);\n\n  var _makeTypesMatch2 = _slicedToArray(_makeTypesMatch, 2);\n\n  $a = _makeTypesMatch2[0];\n  $b = _makeTypesMatch2[1];\n\n  var forward = function forward(backend, save) {\n    save([$a, $b]);\n    var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n    var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n    var outerDimsA = $a.shape.slice(0, -2);\n    var outerDimsB = $b.shape.slice(0, -2);\n    var batchDimA = util.sizeFromShape(outerDimsA);\n    var batchDimB = util.sizeFromShape(outerDimsB);\n    var batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n    util.assert($a.rank >= 2 && $b.rank >= 2 && batchDimsCompatible, function () {\n      return \"Error in matMul: the input batch dimensions must either be the \" + \"same or at least one input batch dimension must be 1. Got input \" + \"batch dimensions of (\".concat(outerDimsA, \") and (\").concat(outerDimsB, \").\");\n    });\n    util.assert(innerShapeA === innerShapeB, function () {\n      return \"Error in matMul: inner shapes (\".concat(innerShapeA, \") and (\") + \"\".concat(innerShapeB, \") of Tensors with shapes \").concat($a.shape, \" and \") + \"\".concat($b.shape, \" and transposeA=\").concat(transposeA) + \" and transposeB=\".concat(transposeB, \" must match.\");\n    });\n    var outShapeOuterDims = batchDimA > batchDimB ? outerDimsA : outerDimsB;\n    var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n    var a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);\n    var b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);\n    var res3d = backend.batchMatMul(a3D, b3D, transposeA, transposeB);\n    return reshape(res3d, outShape);\n  };\n\n  var inputs = {\n    a: $a,\n    b: $b\n  };\n  var attrs = {\n    transposeA: transposeA,\n    transposeB: transposeB\n  };\n  return ENGINE.runKernelFunc(forward, inputs, null\n  /* grad */\n  , BatchMatMul, attrs);\n}\n\nexport var matMul = op({\n  matMul_: matMul_\n});","map":{"version":3,"sources":["../../src/ops/mat_mul.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AACH,SAAQ,MAAR,QAAkC,WAAlC;AACA,SAAQ,WAAR,QAA+D,iBAA/D;AAIA,SAAQ,cAAR,QAA6B,gBAA7B;AACA,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,OAAO,KAAK,IAAZ,MAAsB,SAAtB;AAEA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AAEA;;;;;;;;;;;;;;;AAeG;;AACH,SAAS,OAAT,CACI,CADJ,EAC0B,CAD1B,EAEsB;AAAA,MAD0B,UAC1B,uEADuC,KACvC;AAAA,MAAlB,UAAkB,uEAAL,KAAK;AACpB,MAAI,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,QAAT,CAAxB;AACA,MAAI,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,QAAT,CAAxB;;AAFoB,wBAGT,cAAc,CAAC,EAAD,EAAK,EAAL,CAHL;;AAAA;;AAGnB,EAAA,EAHmB;AAGf,EAAA,EAHe;;AAKpB,MAAM,OAAO,GAAwB,SAA/B,OAA+B,CAAC,OAAD,EAAU,IAAV,EAAkB;AACrD,IAAA,IAAI,CAAC,CAAC,EAAD,EAAK,EAAL,CAAD,CAAJ;AAEA,QAAM,WAAW,GACb,UAAU,GAAG,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CAAH,GAA2B,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CADzC;AAEA,QAAM,WAAW,GACb,UAAU,GAAG,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CAAH,GAA2B,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CADzC;AAGA,QAAM,WAAW,GACb,UAAU,GAAG,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CAAH,GAA2B,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CADzC;AAEA,QAAM,WAAW,GACb,UAAU,GAAG,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CAAH,GAA2B,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,IAAH,GAAU,CAAnB,CADzC;AAGA,QAAM,UAAU,GAAG,EAAE,CAAC,KAAH,CAAS,KAAT,CAAe,CAAf,EAAkB,CAAC,CAAnB,CAAnB;AACA,QAAM,UAAU,GAAG,EAAE,CAAC,KAAH,CAAS,KAAT,CAAe,CAAf,EAAkB,CAAC,CAAnB,CAAnB;AACA,QAAM,SAAS,GAAG,IAAI,CAAC,aAAL,CAAmB,UAAnB,CAAlB;AACA,QAAM,SAAS,GAAG,IAAI,CAAC,aAAL,CAAmB,UAAnB,CAAlB;AAEA,QAAM,mBAAmB,GACrB,SAAS,KAAK,SAAd,IAA2B,SAAS,KAAK,CAAzC,IAA8C,SAAS,KAAK,CADhE;AAGA,IAAA,IAAI,CAAC,MAAL,CACI,EAAE,CAAC,IAAH,IAAW,CAAX,IAAgB,EAAE,CAAC,IAAH,IAAW,CAA3B,IAAgC,mBADpC,EAEI;AAAA,aACI,wKAEwB,UAFxB,oBAE4C,UAF5C,OADJ;AAAA,KAFJ;AAOA,IAAA,IAAI,CAAC,MAAL,CACI,WAAW,KAAK,WADpB,EAEI;AAAA,aAAM,yCAAkC,WAAlC,yBACC,WADD,sCACwC,EAAE,CAAC,KAD3C,uBAEC,EAAE,CAAC,KAFJ,6BAE4B,UAF5B,8BAGiB,UAHjB,iBAAN;AAAA,KAFJ;AAOA,QAAM,iBAAiB,GAAG,SAAS,GAAG,SAAZ,GAAwB,UAAxB,GAAqC,UAA/D;AACA,QAAM,QAAQ,GAAG,iBAAiB,CAAC,MAAlB,CAAyB,CAAC,WAAD,EAAc,WAAd,CAAzB,CAAjB;AAEA,QAAM,GAAG,GAAG,UAAU,GAClB,OAAO,CAAC,EAAD,EAAK,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAL,CADW,GAElB,OAAO,CAAC,EAAD,EAAK,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAL,CAFX;AAGA,QAAM,GAAG,GAAG,UAAU,GAClB,OAAO,CAAC,EAAD,EAAK,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAL,CADW,GAElB,OAAO,CAAC,EAAD,EAAK,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAL,CAFX;AAIA,QAAM,KAAK,GAAG,OAAO,CAAC,WAAR,CACV,GADU,EACO,GADP,EACwB,UADxB,EACoC,UADpC,CAAd;AAEA,WAAO,OAAO,CAAC,KAAD,EAAQ,QAAR,CAAd;AACD,GAhDD;;AAkDA,MAAM,MAAM,GAAsB;AAAC,IAAA,CAAC,EAAE,EAAJ;AAAQ,IAAA,CAAC,EAAE;AAAX,GAAlC;AACA,MAAM,KAAK,GAAqB;AAAC,IAAA,UAAU,EAAV,UAAD;AAAa,IAAA,UAAU,EAAV;AAAb,GAAhC;AAEA,SAAO,MAAM,CAAC,aAAP,CACI,OADJ,EACa,MADb,EAC6C;AAAK;AADlD,IAEI,WAFJ,EAEiB,KAFjB,CAAP;AAGD;;AAED,OAAO,IAAM,MAAM,GAAG,EAAE,CAAC;AAAC,EAAA,OAAO,EAAP;AAAD,CAAD,CAAjB","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { BatchMatMul } from '../kernel_names';\r\nimport { makeTypesMatch } from '../tensor_util';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport * as util from '../util';\r\nimport { op } from './operation';\r\nimport { reshape } from './reshape';\r\n/**\r\n * Computes the dot product of two matrices, A * B. These must be matrices.\r\n *\r\n * ```js\r\n * const a = tf.tensor2d([1, 2], [1, 2]);\r\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\r\n *\r\n * a.matMul(b).print();  // or tf.matMul(a, b)\r\n * ```\r\n * @param a First matrix in dot product operation.\r\n * @param b Second matrix in dot product operation.\r\n * @param transposeA If true, `a` is transposed before multiplication.\r\n * @param transposeB If true, `b` is transposed before multiplication.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Matrices'}\r\n */\r\nfunction matMul_(a, b, transposeA = false, transposeB = false) {\r\n    let $a = convertToTensor(a, 'a', 'matMul');\r\n    let $b = convertToTensor(b, 'b', 'matMul');\r\n    [$a, $b] = makeTypesMatch($a, $b);\r\n    const forward = (backend, save) => {\r\n        save([$a, $b]);\r\n        const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\r\n        const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\r\n        const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\r\n        const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\r\n        const outerDimsA = $a.shape.slice(0, -2);\r\n        const outerDimsB = $b.shape.slice(0, -2);\r\n        const batchDimA = util.sizeFromShape(outerDimsA);\r\n        const batchDimB = util.sizeFromShape(outerDimsB);\r\n        const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\r\n        util.assert($a.rank >= 2 && $b.rank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the ` +\r\n            `same or at least one input batch dimension must be 1. Got input ` +\r\n            `batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);\r\n        util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\r\n            `${innerShapeB}) of Tensors with shapes ${$a.shape} and ` +\r\n            `${$b.shape} and transposeA=${transposeA}` +\r\n            ` and transposeB=${transposeB} must match.`);\r\n        const outShapeOuterDims = batchDimA > batchDimB ? outerDimsA : outerDimsB;\r\n        const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\r\n        const a3D = transposeA ?\r\n            reshape($a, [batchDimA, innerShapeA, outerShapeA]) :\r\n            reshape($a, [batchDimA, outerShapeA, innerShapeA]);\r\n        const b3D = transposeB ?\r\n            reshape($b, [batchDimB, outerShapeB, innerShapeB]) :\r\n            reshape($b, [batchDimB, innerShapeB, outerShapeB]);\r\n        const res3d = backend.batchMatMul(a3D, b3D, transposeA, transposeB);\r\n        return reshape(res3d, outShape);\r\n    };\r\n    const inputs = { a: $a, b: $b };\r\n    const attrs = { transposeA, transposeB };\r\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, BatchMatMul, attrs);\r\n}\r\nexport const matMul = op({ matMul_ });\r\n//# sourceMappingURL=mat_mul.js.map"]},"metadata":{},"sourceType":"module"}