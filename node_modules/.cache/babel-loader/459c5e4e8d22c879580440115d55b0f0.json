{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { FusedBatchNorm } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { xAs4D } from './batchnorm_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\r\n * Batch normalization.\r\n *\r\n * As described in\r\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\r\n *\r\n * Mean, variance, scale, and offset can be of two shapes:\r\n *   - The same shape as the input.\r\n *   - In the common case, the depth dimension is the last dimension of x, so\r\n *     the values would be an `tf.Tensor1D` of shape [depth].\r\n *\r\n * Also available are stricter rank-specific methods with the same signature\r\n * as this method that assert that parameters passed are of given rank\r\n *   - `tf.batchNorm2d`\r\n *   - `tf.batchNorm3d`\r\n *   - `tf.batchNorm4d`\r\n *\r\n * @param x The input Tensor.\r\n * @param mean A mean Tensor.\r\n * @param variance A variance Tensor.\r\n * @param offset An offset Tensor.\r\n * @param scale A scale Tensor.\r\n * @param varianceEpsilon A small float number to avoid dividing by 0.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Normalization'}\r\n */\n\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const $x = convertToTensor(x, 'x', 'batchNorm');\n  const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n  const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n  let $scale;\n\n  if (scale != null) {\n    $scale = convertToTensor(scale, 'scale', 'batchNorm');\n  }\n\n  let $offset;\n\n  if (offset != null) {\n    $offset = convertToTensor(offset, 'offset', 'batchNorm');\n  }\n\n  util.assert($mean.rank === $variance.rank, () => 'Batch normalization gradient requires mean and variance to have ' + 'equal ranks.');\n  util.assert($offset == null || $mean.rank === $offset.rank, () => 'Batch normalization gradient requires mean and offset to have ' + 'equal ranks.');\n  util.assert($scale == null || $mean.rank === $scale.rank, () => 'Batch normalization gradient requires mean and scale to have ' + 'equal ranks.');\n  const x4D = xAs4D($x);\n\n  const forward = (backend, save) => {\n    save([x4D, $mean, $variance, $scale]);\n    return backend.batchNorm(x4D, as1DOr4D($mean), as1DOr4D($variance), as1DOr4D($offset), as1DOr4D($scale), varianceEpsilon);\n  };\n\n  const inputs = {\n    x: x4D,\n    scale: $scale,\n    offset: $offset,\n    mean: $mean,\n    variance: $variance\n  };\n  const attrs = {\n    varianceEpsilon\n  };\n  const res = ENGINE.runKernelFunc(forward, inputs, null\n  /* gradient */\n  , FusedBatchNorm, attrs);\n  return reshape(res, $x.shape);\n}\n\nfunction as1DOr4D(x) {\n  if (x == null) {\n    return null;\n  }\n\n  if (x.rank === 0) {\n    // tslint:disable-next-line:no-unnecessary-type-assertion\n    return reshape(x, [x.size]);\n  } else if (x.rank === 1) {\n    return x;\n  } else if (x.rank === 2) {\n    // tslint:disable-next-line:no-unnecessary-type-assertion\n    return reshape(x, [1, 1, x.shape[0], x.shape[1]]);\n  } else if (x.rank === 3) {\n    // tslint:disable-next-line:no-unnecessary-type-assertion\n    return reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n  }\n\n  return x;\n}\n\nexport const batchNorm = op({\n  batchNorm_\n});","map":{"version":3,"sources":["../../src/ops/batchnorm.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAkC,WAAlC;AACA,SAAQ,cAAR,QAAwE,iBAAxE;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,OAAO,KAAK,IAAZ,MAAsB,SAAtB;AAEA,SAAQ,KAAR,QAAoB,kBAApB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;AAyBG;;AACH,SAAS,UAAT,CACI,CADJ,EAC6B,IAD7B,EAEI,QAFJ,EAGI,MAHJ,EAII,KAJJ,EAKI,eALJ,EAK4B;AAC1B,MAAI,eAAe,IAAI,IAAvB,EAA6B;AAC3B,IAAA,eAAe,GAAG,KAAlB;AACD;;AACD,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,QAAM,KAAK,GAAG,eAAe,CAAC,IAAD,EAAO,MAAP,EAAe,WAAf,CAA7B;AACA,QAAM,SAAS,GAAG,eAAe,CAAC,QAAD,EAAW,UAAX,EAAuB,WAAvB,CAAjC;AACA,MAAI,MAAJ;;AACA,MAAI,KAAK,IAAI,IAAb,EAAmB;AACjB,IAAA,MAAM,GAAG,eAAe,CAAC,KAAD,EAAQ,OAAR,EAAiB,WAAjB,CAAxB;AACD;;AACD,MAAI,OAAJ;;AACA,MAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,IAAA,OAAO,GAAG,eAAe,CAAC,MAAD,EAAS,QAAT,EAAmB,WAAnB,CAAzB;AACD;;AAED,EAAA,IAAI,CAAC,MAAL,CACI,KAAK,CAAC,IAAN,KAAe,SAAS,CAAC,IAD7B,EAEI,MAAM,qEACF,cAHR;AAIA,EAAA,IAAI,CAAC,MAAL,CACI,OAAO,IAAI,IAAX,IAAmB,KAAK,CAAC,IAAN,KAAe,OAAO,CAAC,IAD9C,EAEI,MAAM,mEACF,cAHR;AAIA,EAAA,IAAI,CAAC,MAAL,CACI,MAAM,IAAI,IAAV,IAAkB,KAAK,CAAC,IAAN,KAAe,MAAM,CAAC,IAD5C,EAEI,MAAM,kEACF,cAHR;AAKA,QAAM,GAAG,GAAa,KAAK,CAAC,EAAD,CAA3B;;AAEA,QAAM,OAAO,GAAwB,CAAC,OAAD,EAAU,IAAV,KAAkB;AACrD,IAAA,IAAI,CAAC,CAAC,GAAD,EAAM,KAAN,EAAa,SAAb,EAAwB,MAAxB,CAAD,CAAJ;AAEA,WAAO,OAAO,CAAC,SAAR,CACH,GADG,EACE,QAAQ,CAAC,KAAD,CADV,EACmB,QAAQ,CAAC,SAAD,CAD3B,EACwC,QAAQ,CAAC,OAAD,CADhD,EAEH,QAAQ,CAAC,MAAD,CAFL,EAEe,eAFf,CAAP;AAGD,GAND;;AAQA,QAAM,MAAM,GAAyB;AACnC,IAAA,CAAC,EAAE,GADgC;AAEnC,IAAA,KAAK,EAAE,MAF4B;AAGnC,IAAA,MAAM,EAAE,OAH2B;AAInC,IAAA,IAAI,EAAE,KAJ6B;AAKnC,IAAA,QAAQ,EAAE;AALyB,GAArC;AAQA,QAAM,KAAK,GAAwB;AAAC,IAAA;AAAD,GAAnC;AAEA,QAAM,GAAG,GAAG,MAAM,CAAC,aAAP,CACR,OADQ,EACC,MADD,EACiC;AAAK;AADtC,IAER,cAFQ,EAEQ,KAFR,CAAZ;AAIA,SAAO,OAAO,CAAC,GAAD,EAAM,EAAE,CAAC,KAAT,CAAd;AACD;;AAED,SAAS,QAAT,CAAkB,CAAlB,EAA2B;AACzB,MAAI,CAAC,IAAI,IAAT,EAAe;AACb,WAAO,IAAP;AACD;;AACD,MAAI,CAAC,CAAC,IAAF,KAAW,CAAf,EAAkB;AAChB;AACA,WAAO,OAAO,CAAC,CAAD,EAAI,CAAC,CAAC,CAAC,IAAH,CAAJ,CAAd;AACD,GAHD,MAGO,IAAI,CAAC,CAAC,IAAF,KAAW,CAAf,EAAkB;AACvB,WAAO,CAAP;AACD,GAFM,MAEA,IAAI,CAAC,CAAC,IAAF,KAAW,CAAf,EAAkB;AACvB;AACA,WAAO,OAAO,CAAC,CAAD,EAAI,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAC,CAAC,KAAF,CAAQ,CAAR,CAAP,EAAmB,CAAC,CAAC,KAAF,CAAQ,CAAR,CAAnB,CAAJ,CAAd;AACD,GAHM,MAGA,IAAI,CAAC,CAAC,IAAF,KAAW,CAAf,EAAkB;AACvB;AACA,WAAO,OAAO,CAAC,CAAD,EAAI,CAAC,CAAD,EAAI,CAAC,CAAC,KAAF,CAAQ,CAAR,CAAJ,EAAgB,CAAC,CAAC,KAAF,CAAQ,CAAR,CAAhB,EAA4B,CAAC,CAAC,KAAF,CAAQ,CAAR,CAA5B,CAAJ,CAAd;AACD;;AACD,SAAO,CAAP;AACD;;AAED,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { FusedBatchNorm } from '../kernel_names';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport * as util from '../util';\r\nimport { xAs4D } from './batchnorm_util';\r\nimport { op } from './operation';\r\nimport { reshape } from './reshape';\r\n/**\r\n * Batch normalization.\r\n *\r\n * As described in\r\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\r\n *\r\n * Mean, variance, scale, and offset can be of two shapes:\r\n *   - The same shape as the input.\r\n *   - In the common case, the depth dimension is the last dimension of x, so\r\n *     the values would be an `tf.Tensor1D` of shape [depth].\r\n *\r\n * Also available are stricter rank-specific methods with the same signature\r\n * as this method that assert that parameters passed are of given rank\r\n *   - `tf.batchNorm2d`\r\n *   - `tf.batchNorm3d`\r\n *   - `tf.batchNorm4d`\r\n *\r\n * @param x The input Tensor.\r\n * @param mean A mean Tensor.\r\n * @param variance A variance Tensor.\r\n * @param offset An offset Tensor.\r\n * @param scale A scale Tensor.\r\n * @param varianceEpsilon A small float number to avoid dividing by 0.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Normalization'}\r\n */\r\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\r\n    if (varianceEpsilon == null) {\r\n        varianceEpsilon = 0.001;\r\n    }\r\n    const $x = convertToTensor(x, 'x', 'batchNorm');\r\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\r\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\r\n    let $scale;\r\n    if (scale != null) {\r\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\r\n    }\r\n    let $offset;\r\n    if (offset != null) {\r\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\r\n    }\r\n    util.assert($mean.rank === $variance.rank, () => 'Batch normalization gradient requires mean and variance to have ' +\r\n        'equal ranks.');\r\n    util.assert($offset == null || $mean.rank === $offset.rank, () => 'Batch normalization gradient requires mean and offset to have ' +\r\n        'equal ranks.');\r\n    util.assert($scale == null || $mean.rank === $scale.rank, () => 'Batch normalization gradient requires mean and scale to have ' +\r\n        'equal ranks.');\r\n    const x4D = xAs4D($x);\r\n    const forward = (backend, save) => {\r\n        save([x4D, $mean, $variance, $scale]);\r\n        return backend.batchNorm(x4D, as1DOr4D($mean), as1DOr4D($variance), as1DOr4D($offset), as1DOr4D($scale), varianceEpsilon);\r\n    };\r\n    const inputs = {\r\n        x: x4D,\r\n        scale: $scale,\r\n        offset: $offset,\r\n        mean: $mean,\r\n        variance: $variance\r\n    };\r\n    const attrs = { varianceEpsilon };\r\n    const res = ENGINE.runKernelFunc(forward, inputs, null /* gradient */, FusedBatchNorm, attrs);\r\n    return reshape(res, $x.shape);\r\n}\r\nfunction as1DOr4D(x) {\r\n    if (x == null) {\r\n        return null;\r\n    }\r\n    if (x.rank === 0) {\r\n        // tslint:disable-next-line:no-unnecessary-type-assertion\r\n        return reshape(x, [x.size]);\r\n    }\r\n    else if (x.rank === 1) {\r\n        return x;\r\n    }\r\n    else if (x.rank === 2) {\r\n        // tslint:disable-next-line:no-unnecessary-type-assertion\r\n        return reshape(x, [1, 1, x.shape[0], x.shape[1]]);\r\n    }\r\n    else if (x.rank === 3) {\r\n        // tslint:disable-next-line:no-unnecessary-type-assertion\r\n        return reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\r\n    }\r\n    return x;\r\n}\r\nexport const batchNorm = op({ batchNorm_ });\r\n//# sourceMappingURL=batchnorm.js.map"]},"metadata":{},"sourceType":"module"}