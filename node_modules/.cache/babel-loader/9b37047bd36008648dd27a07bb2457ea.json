{"ast":null,"code":"import _slicedToArray from \"C:/Users/wongh/Documents/GitHub/tfjs-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { Softmax } from '../kernel_names';\nimport { mul } from '../ops/mul';\nimport { sub } from '../ops/sub';\nimport { sum } from '../ops/sum';\nexport var softmaxGradConfig = {\n  kernelName: Softmax,\n  outputsToSave: [true],\n  gradFunc: function gradFunc(dy, saved, attrs) {\n    var _saved = _slicedToArray(saved, 1),\n        y = _saved[0];\n\n    var dim = attrs.dim;\n    var keepDims = true;\n    var dyTimesY = mul(dy, y);\n    return {\n      logits: function logits() {\n        return sub(dyTimesY, mul(sum(dyTimesY, [dim], keepDims), y));\n      }\n    };\n  }\n};","map":{"version":3,"sources":["../../src/gradients/Softmax_grad.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,OAAR,QAAoC,iBAApC;AAEA,SAAQ,GAAR,QAAkB,YAAlB;AACA,SAAQ,GAAR,QAAkB,YAAlB;AACA,SAAQ,GAAR,QAAkB,YAAlB;AAGA,OAAO,IAAM,iBAAiB,GAAe;AAC3C,EAAA,UAAU,EAAE,OAD+B;AAE3C,EAAA,aAAa,EAAE,CAAC,IAAD,CAF4B;AAG3C,EAAA,QAAQ,EAAE,kBAAC,EAAD,EAAa,KAAb,EAA8B,KAA9B,EAAqD;AAAA,gCACjD,KADiD;AAAA,QACtD,CADsD;;AAAA,QAEtD,GAFsD,GAE/C,KAF+C,CAEtD,GAFsD;AAG7D,QAAM,QAAQ,GAAG,IAAjB;AAEA,QAAM,QAAQ,GAAG,GAAG,CAAC,EAAD,EAAK,CAAL,CAApB;AACA,WAAO;AACL,MAAA,MAAM,EAAE;AAAA,eAAM,GAAG,CAAC,QAAD,EAAW,GAAG,CAAC,GAAG,CAAC,QAAD,EAAW,CAAC,GAAD,CAAX,EAAkB,QAAlB,CAAJ,EAAiC,CAAjC,CAAd,CAAT;AAAA;AADH,KAAP;AAGD;AAZ0C,CAAtC","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { Softmax } from '../kernel_names';\r\nimport { mul } from '../ops/mul';\r\nimport { sub } from '../ops/sub';\r\nimport { sum } from '../ops/sum';\r\nexport const softmaxGradConfig = {\r\n    kernelName: Softmax,\r\n    outputsToSave: [true],\r\n    gradFunc: (dy, saved, attrs) => {\r\n        const [y] = saved;\r\n        const { dim } = attrs;\r\n        const keepDims = true;\r\n        const dyTimesY = mul(dy, y);\r\n        return {\r\n            logits: () => sub(dyTimesY, mul(sum(dyTimesY, [dim], keepDims), y))\r\n        };\r\n    }\r\n};\r\n//# sourceMappingURL=Softmax_grad.js.map"]},"metadata":{},"sourceType":"module"}