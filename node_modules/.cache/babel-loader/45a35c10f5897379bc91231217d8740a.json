{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { BroadcastTo } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\r\n * Broadcast an array to a compatible shape NumPy-style.\r\n *\r\n * The tensor's shape is compared to the broadcast shape from end to beginning.\r\n * Ones are prepended to the tensor's shape until is has the same length as\r\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\r\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\r\n * the input tensor is tiled N times along that axis (using tf.tile).\r\n *\r\n * @param input The tensor that is to be broadcasted.\r\n * @param shape The input is to be broadcast to this shape.\r\n *\r\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\r\n */\n\nfunction broadcastTo_(x, shape) {\n  let input = convertToTensor(x, 'broadcastTo', 'x');\n  const xShape = input.shape;\n\n  if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n  }\n\n  if (shape.length < input.rank) {\n    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n  }\n\n  if (shape.length > input.rank) {\n    const newShape = input.shape.slice();\n\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n\n    input = reshape(input, newShape);\n  }\n\n  const inputShape = input.shape;\n  const reps = Array.from(shape);\n\n  for (let i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n    }\n  }\n\n  const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n\n  if (axes.length === 0) {\n    return clone(input);\n  }\n\n  const forward = backend => backend.tile(input, reps);\n\n  const inputs = {\n    x: input\n  };\n  const attrs = {\n    shape,\n    inputShape\n  };\n  return ENGINE.runKernelFunc(forward, inputs, null\n  /* grad */\n  , BroadcastTo, attrs);\n}\n\nexport const broadcastTo = op({\n  broadcastTo_\n});","map":{"version":3,"sources":["../../src/ops/broadcast_to.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAGH,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,WAAR,QAA+D,iBAA/D;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,KAAR,QAAoB,SAApB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AAEA;;;;;;;;;;;;;AAaG;;AACH,SAAS,YAAT,CACI,CADJ,EAC0B,KAD1B,EAC4C;AAC1C,MAAI,KAAK,GAAG,eAAe,CAAC,CAAD,EAAI,aAAJ,EAAmB,GAAnB,CAA3B;AACA,QAAM,MAAM,GAAG,KAAK,CAAC,KAArB;;AAEA,MAAI,KAAK,CAAC,IAAN,CAAW,CAAC,IAAI,EAAE,CAAC,GAAG,CAAN,KAAY,CAAC,GAAG,CAAJ,KAAU,CAAtC,CAAJ,EAA8C;AAC5C,UAAM,IAAI,KAAJ,CAAU,2CAA2C,KAAK,IAA1D,CAAN;AACD;;AAED,MAAI,KAAK,CAAC,MAAN,GAAe,KAAK,CAAC,IAAzB,EAA+B;AAC7B,UAAM,IAAI,KAAJ,CAAU,+BAA+B,KAAK,CAAC,MAAM,iBACvD,KAAK,CAAC,IAAI,GADR,CAAN;AAED;;AAED,MAAI,KAAK,CAAC,MAAN,GAAe,KAAK,CAAC,IAAzB,EAA+B;AAC7B,UAAM,QAAQ,GAAG,KAAK,CAAC,KAAN,CAAY,KAAZ,EAAjB;;AACA,WAAO,QAAQ,CAAC,MAAT,GAAkB,KAAK,CAAC,MAA/B,EAAuC;AACrC,MAAA,QAAQ,CAAC,OAAT,CAAiB,CAAjB;AACD;;AACD,IAAA,KAAK,GAAG,OAAO,CAAC,KAAD,EAAQ,QAAR,CAAf;AACD;;AAED,QAAM,UAAU,GAAG,KAAK,CAAC,KAAzB;AACA,QAAM,IAAI,GAAa,KAAK,CAAC,IAAN,CAAW,KAAX,CAAvB;;AACA,OAAK,IAAI,CAAC,GAAG,KAAK,CAAC,MAAN,GAAe,CAA5B,EAA+B,CAAC,IAAI,CAApC,EAAuC,CAAC,EAAxC,EAA4C;AAC1C,QAAI,UAAU,CAAC,CAAD,CAAV,KAAkB,KAAK,CAAC,CAAD,CAA3B,EAAgC;AAC9B,MAAA,IAAI,CAAC,CAAD,CAAJ,GAAU,CAAV;AACD,KAFD,MAEO,IAAI,KAAK,CAAC,KAAN,CAAY,CAAZ,MAAmB,CAAvB,EAA0B;AAC/B,YAAM,IAAI,KAAJ,CACF,mBAAmB,MAAM,6BAA6B,KAAK,IADzD,CAAN;AAED;AACF;;AACD,QAAM,IAAI,GAAG,IAAI,CAAC,GAAL,CAAS,CAAC,CAAD,EAAI,CAAJ,KAAU,CAAC,GAAG,CAAJ,GAAQ,CAAR,GAAY,CAAC,CAAhC,EAAmC,MAAnC,CAA0C,CAAC,IAAI,CAAC,IAAI,CAApD,CAAb;;AAEA,MAAI,IAAI,CAAC,MAAL,KAAgB,CAApB,EAAuB;AACrB,WAAO,KAAK,CAAC,KAAD,CAAZ;AACD;;AAED,QAAM,OAAO,GAAI,OAAD,IAA4B,OAAO,CAAC,IAAR,CAAa,KAAb,EAAoB,IAApB,CAA5C;;AAEA,QAAM,MAAM,GAAsB;AAAC,IAAA,CAAC,EAAE;AAAJ,GAAlC;AACA,QAAM,KAAK,GAAqB;AAAC,IAAA,KAAD;AAAQ,IAAA;AAAR,GAAhC;AAEA,SAAO,MAAM,CAAC,aAAP,CACI,OADJ,EACa,MADb,EACkD;AAAK;AADvD,IAEI,WAFJ,EAEiB,KAFjB,CAAP;AAGD;;AAED,OAAO,MAAM,WAAW,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAtB","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { BroadcastTo } from '../kernel_names';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport { clone } from './clone';\r\nimport { op } from './operation';\r\nimport { reshape } from './reshape';\r\n/**\r\n * Broadcast an array to a compatible shape NumPy-style.\r\n *\r\n * The tensor's shape is compared to the broadcast shape from end to beginning.\r\n * Ones are prepended to the tensor's shape until is has the same length as\r\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\r\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\r\n * the input tensor is tiled N times along that axis (using tf.tile).\r\n *\r\n * @param input The tensor that is to be broadcasted.\r\n * @param shape The input is to be broadcast to this shape.\r\n *\r\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\r\n */\r\nfunction broadcastTo_(x, shape) {\r\n    let input = convertToTensor(x, 'broadcastTo', 'x');\r\n    const xShape = input.shape;\r\n    if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\r\n        throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\r\n    }\r\n    if (shape.length < input.rank) {\r\n        throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\r\n    }\r\n    if (shape.length > input.rank) {\r\n        const newShape = input.shape.slice();\r\n        while (newShape.length < shape.length) {\r\n            newShape.unshift(1);\r\n        }\r\n        input = reshape(input, newShape);\r\n    }\r\n    const inputShape = input.shape;\r\n    const reps = Array.from(shape);\r\n    for (let i = shape.length - 1; i >= 0; i--) {\r\n        if (inputShape[i] === shape[i]) {\r\n            reps[i] = 1;\r\n        }\r\n        else if (input.shape[i] !== 1) {\r\n            throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\r\n        }\r\n    }\r\n    const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\r\n    if (axes.length === 0) {\r\n        return clone(input);\r\n    }\r\n    const forward = (backend) => backend.tile(input, reps);\r\n    const inputs = { x: input };\r\n    const attrs = { shape, inputShape };\r\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, BroadcastTo, attrs);\r\n}\r\nexport const broadcastTo = op({ broadcastTo_ });\r\n//# sourceMappingURL=broadcast_to.js.map"]},"metadata":{},"sourceType":"module"}