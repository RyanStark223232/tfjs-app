{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { Mod } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\r\n * Returns the mod of a and b element-wise.\r\n * `floor(x / y) * y + mod(x, y) = x`\r\n * Supports broadcasting.\r\n *\r\n * We also expose `tf.modStrict` which has the same signature as this op and\r\n * asserts that `a` and `b` are the same shape (does not broadcast).\r\n *\r\n * ```js\r\n * const a = tf.tensor1d([1, 4, 3, 16]);\r\n * const b = tf.tensor1d([1, 2, 9, 4]);\r\n *\r\n * a.mod(b).print();  // or tf.mod(a, b)\r\n * ```\r\n *\r\n * ```js\r\n * // Broadcast a mod b.\r\n * const a = tf.tensor1d([2, 4, 6, 8]);\r\n * const b = tf.scalar(5);\r\n *\r\n * a.mod(b).print();  // or tf.mod(a, b)\r\n * ```\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same type as `a`.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\r\n */\n\nfunction mod_(a, b) {\n  let $a = convertToTensor(a, 'a', 'mod');\n  let $b = convertToTensor(b, 'b', 'mod');\n  [$a, $b] = makeTypesMatch($a, $b);\n\n  const forward = (backend, save) => {\n    const res = backend.mod($a, $b);\n    save([$a, $b]);\n    return res;\n  };\n\n  const inputs = {\n    a: $a,\n    b: $b\n  };\n  return ENGINE.runKernelFunc(forward, inputs, null\n  /* gradient */\n  , Mod);\n}\n\nexport const mod = op({\n  mod_\n});","map":{"version":3,"sources":["../../src/ops/mod.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAkC,WAAlC;AACA,SAAQ,GAAR,QAA6B,iBAA7B;AAGA,SAAQ,cAAR,QAA6B,gBAA7B;AACA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,EAAR,QAAiB,aAAjB;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2BG;;AACH,SAAS,IAAT,CAAgC,CAAhC,EAAsD,CAAtD,EAA0E;AACxE,MAAI,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAAxB;AACA,MAAI,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAAxB;AACA,GAAC,EAAD,EAAK,EAAL,IAAW,cAAc,CAAC,EAAD,EAAK,EAAL,CAAzB;;AAEA,QAAM,OAAO,GAAwB,CAAC,OAAD,EAAU,IAAV,KAAkB;AACrD,UAAM,GAAG,GAAG,OAAO,CAAC,GAAR,CAAY,EAAZ,EAAgB,EAAhB,CAAZ;AACA,IAAA,IAAI,CAAC,CAAC,EAAD,EAAK,EAAL,CAAD,CAAJ;AACA,WAAO,GAAP;AACD,GAJD;;AAKA,QAAM,MAAM,GAAc;AAAC,IAAA,CAAC,EAAE,EAAJ;AAAQ,IAAA,CAAC,EAAE;AAAX,GAA1B;AAEA,SAAO,MAAM,CAAC,aAAP,CACI,OADJ,EACa,MADb,EAC6C;AAAK;AADlD,IAEI,GAFJ,CAAP;AAGD;;AAED,OAAO,MAAM,GAAG,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAd","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { Mod } from '../kernel_names';\r\nimport { makeTypesMatch } from '../tensor_util';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport { op } from './operation';\r\n/**\r\n * Returns the mod of a and b element-wise.\r\n * `floor(x / y) * y + mod(x, y) = x`\r\n * Supports broadcasting.\r\n *\r\n * We also expose `tf.modStrict` which has the same signature as this op and\r\n * asserts that `a` and `b` are the same shape (does not broadcast).\r\n *\r\n * ```js\r\n * const a = tf.tensor1d([1, 4, 3, 16]);\r\n * const b = tf.tensor1d([1, 2, 9, 4]);\r\n *\r\n * a.mod(b).print();  // or tf.mod(a, b)\r\n * ```\r\n *\r\n * ```js\r\n * // Broadcast a mod b.\r\n * const a = tf.tensor1d([2, 4, 6, 8]);\r\n * const b = tf.scalar(5);\r\n *\r\n * a.mod(b).print();  // or tf.mod(a, b)\r\n * ```\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same type as `a`.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\r\n */\r\nfunction mod_(a, b) {\r\n    let $a = convertToTensor(a, 'a', 'mod');\r\n    let $b = convertToTensor(b, 'b', 'mod');\r\n    [$a, $b] = makeTypesMatch($a, $b);\r\n    const forward = (backend, save) => {\r\n        const res = backend.mod($a, $b);\r\n        save([$a, $b]);\r\n        return res;\r\n    };\r\n    const inputs = { a: $a, b: $b };\r\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Mod);\r\n}\r\nexport const mod = op({ mod_ });\r\n//# sourceMappingURL=mod.js.map"]},"metadata":{},"sourceType":"module"}