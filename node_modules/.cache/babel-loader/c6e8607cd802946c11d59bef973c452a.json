{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from './engine';\nimport { env } from './environment';\nimport { setDeprecationWarningFn } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\n/**\r\n * Enables production mode which disables correctness checks in favor of\r\n * performance.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\n\nexport function enableProdMode() {\n  env().set('PROD', true);\n}\n/**\r\n * Enables debug mode which will log information about all executed kernels:\r\n * the elapsed time of the kernel execution, as well as the rank, shape, and\r\n * size of the output tensor.\r\n *\r\n * Debug mode will significantly slow down your application as it will\r\n * download the result of every operation to the CPU. This should not be used in\r\n * production. Debug mode does not affect the timing information of the kernel\r\n * execution as we do not measure download time in the kernel execution time.\r\n *\r\n * See also: `tf.profile`, `tf.memory`.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\n\nexport function enableDebugMode() {\n  env().set('DEBUG', true);\n}\n/** Globally disables deprecation warnings */\n\nexport function disableDeprecationWarnings() {\n  env().set('DEPRECATION_WARNINGS_ENABLED', false);\n  console.warn(\"TensorFlow.js deprecation warnings have been disabled.\");\n}\n/** Warn users about deprecated functionality. */\n\nexport function deprecationWarn(msg) {\n  if (env().getBool('DEPRECATION_WARNINGS_ENABLED')) {\n    console.warn(msg + ' You can disable deprecation warnings with ' + 'tf.disableDeprecationWarnings().');\n  }\n}\nsetDeprecationWarningFn(deprecationWarn);\n/**\r\n * Dispose all variables kept in backend engine.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\n\nexport function disposeVariables() {\n  ENGINE.disposeVariables();\n}\n/**\r\n * It returns the global engine that keeps track of all tensors and backends.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\n\nexport function engine() {\n  return ENGINE;\n}\n/**\r\n * Returns memory info at the current time in the program. The result is an\r\n * object with the following properties:\r\n *\r\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\r\n * - `numTensors`: Number of unique tensors allocated.\r\n * - `numDataBuffers`: Number of unique data buffers allocated\r\n *   (undisposed) at this time, which is ≤ the number of tensors\r\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\r\n *   data buffer with `a`).\r\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\r\n *    `unreliable` is true.\r\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\r\n *    `unreliable` is true.\r\n *\r\n * WebGL Properties:\r\n * - `numBytesInGPU`: Number of bytes allocated (undisposed) in the GPU only at\r\n *     this time.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\n\nexport function memory() {\n  return ENGINE.memory();\n}\n/**\r\n * Executes the provided function `f()` and returns a promise that resolves\r\n * with information about the function's memory use:\r\n * - `newBytes`: the number of new bytes allocated\r\n * - `newTensors`: the number of new tensors created\r\n * - `peakBytes`: the peak number of bytes allocated\r\n * - `kernels`: an array of objects for each kernel involved that reports\r\n * their input and output shapes, number of bytes used, and number of new\r\n * tensors created.\r\n *\r\n * ```js\r\n * const profile = await tf.profile(() => {\r\n *   const x = tf.tensor1d([1, 2, 3]);\r\n *   let x2 = x.square();\r\n *   x2.dispose();\r\n *   x2 = x.square();\r\n *   x2.dispose();\r\n *   return x;\r\n * });\r\n *\r\n * console.log(`newBytes: ${profile.newBytes}`);\r\n * console.log(`newTensors: ${profile.newTensors}`);\r\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\r\n * k.totalBytesSnapshot)}`);\r\n * ```\r\n *\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Profile'}\r\n */\n\nexport function profile(f) {\n  return ENGINE.profile(f);\n}\n/**\r\n * Executes the provided function `fn` and after it is executed, cleans up all\r\n * intermediate tensors allocated by `fn` except those returned by `fn`.\r\n * `fn` must not return a Promise (async functions not allowed). The returned\r\n * result can be a complex object.\r\n *\r\n * Using this method helps avoid memory leaks. In general, wrap calls to\r\n * operations in `tf.tidy` for automatic memory cleanup.\r\n *\r\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\r\n * dispose variables, please use `tf.disposeVariables` or call dispose()\r\n * directly on variables.\r\n *\r\n * ```js\r\n * // y = 2 ^ 2 + 1\r\n * const y = tf.tidy(() => {\r\n *   // a, b, and one will be cleaned up when the tidy ends.\r\n *   const one = tf.scalar(1);\r\n *   const a = tf.scalar(2);\r\n *   const b = a.square();\r\n *\r\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\r\n *\r\n *   // The value returned inside the tidy function will return\r\n *   // through the tidy, in this case to the variable y.\r\n *   return b.add(one);\r\n * });\r\n *\r\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\r\n * y.print();\r\n * ```\r\n *\r\n * @param nameOrFn The name of the closure, or the function to execute.\r\n *     If a name is provided, the 2nd argument should be the function.\r\n *     If debug mode is on, the timing and the memory usage of the function\r\n *     will be tracked and displayed on the console using the provided name.\r\n * @param fn The function to execute.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\n\nexport function tidy(nameOrFn, fn) {\n  return ENGINE.tidy(nameOrFn, fn);\n}\n/**\r\n * Disposes any `tf.Tensor`s found within the provided object.\r\n *\r\n * @param container an object that may be a `tf.Tensor` or may directly\r\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\r\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\r\n *     happens. In general it is safe to pass any object here, except that\r\n *     `Promise`s are not supported.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\n\nexport function dispose(container) {\n  var tensors = getTensorsInContainer(container);\n  tensors.forEach(function (tensor) {\n    return tensor.dispose();\n  });\n}\n/**\r\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\r\n * automatically.\r\n *\r\n * ```js\r\n * let b;\r\n * const y = tf.tidy(() => {\r\n *   const one = tf.scalar(1);\r\n *   const a = tf.scalar(2);\r\n *\r\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\r\n *   // when the tidy ends.\r\n *   b = tf.keep(a.square());\r\n *\r\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\r\n *\r\n *   // The value returned inside the tidy function will return\r\n *   // through the tidy, in this case to the variable y.\r\n *   return b.add(one);\r\n * });\r\n *\r\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\r\n * console.log('y:');\r\n * y.print();\r\n * console.log('b:');\r\n * b.print();\r\n * ```\r\n *\r\n * @param result The tensor to keep from being disposed.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\n\nexport function keep(result) {\n  return ENGINE.keep(result);\n}\n/**\r\n * Executes `f()` and returns a promise that resolves with timing\r\n * information.\r\n *\r\n * The result is an object with the following properties:\r\n *\r\n * - `wallMs`: Wall execution time.\r\n * - `kernelMs`: Kernel execution time, ignoring data transfer. If using the\r\n * WebGL backend and the query timer extension is not available, this will\r\n * return an error object.\r\n * - On `WebGL` The following additional properties exist:\r\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\r\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\r\n *\r\n * ```js\r\n * const x = tf.randomNormal([20, 20]);\r\n * const time = await tf.time(() => x.matMul(x));\r\n *\r\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\r\n * ```\r\n *\r\n * @param f The function to execute and time.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Timing'}\r\n */\n\nexport function time(f) {\n  return ENGINE.time(f);\n}\n/**\r\n * Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and\r\n * executing operations on those tensors. Returns a promise that resolves\r\n * to a boolean if the backend initialization was successful.\r\n *\r\n * Note this disposes the current backend, if any, as well as any tensors\r\n * associated with it. A new backend is initialized, even if it is of the\r\n * same type as the previous one.\r\n *\r\n * @param backendName The name of the backend. Currently supports\r\n *     `'webgl'|'cpu'` in the browser, `'tensorflow'` under node.js\r\n *     (requires tfjs-node), and `'wasm'` (requires tfjs-backend-wasm).\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\n\nexport function setBackend(backendName) {\n  return ENGINE.setBackend(backendName);\n}\n/**\r\n * Returns a promise that resolves when the currently selected backend (or the\r\n * highest priority one) has initialized. Await this promise when you are using\r\n * a backend that has async initialization.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\n\nexport function ready() {\n  return ENGINE.ready();\n}\n/**\r\n * Returns the current backend name (cpu, webgl, etc). The backend is\r\n * responsible for creating tensors and executing operations on those tensors.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\n\nexport function getBackend() {\n  return ENGINE.backendName;\n}\n/**\r\n * Removes a backend and the registered factory.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\n\nexport function removeBackend(name) {\n  ENGINE.removeBackend(name);\n}\n/**\r\n * Finds the backend registered under the provided name. Returns null if the\r\n * name is not in the registry, or the registration hasn't finished yet.\r\n */\n\nexport function findBackend(name) {\n  return ENGINE.findBackend(name);\n}\n/**\r\n * Finds the backend factory registered under the provided name. Returns a\r\n * function that produces a new backend when called. Returns null if the name\r\n * is not in the registry.\r\n */\n\nexport function findBackendFactory(name) {\n  return ENGINE.findBackendFactory(name);\n}\n/**\r\n * Registers a global backend. The registration should happen when importing\r\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\r\n * modular builds (e.g. custom tfjs bundle with only webgl support).\r\n *\r\n * @param factory The backend factory function. When called, it should\r\n * return a backend instance, or a promise of an instance.\r\n * @param priority The priority of the backend (higher = more important).\r\n *     In case multiple backends are registered, the priority is used to find\r\n *     the best backend. Defaults to 1.\r\n * @return False if there is already a registered backend under this name, true\r\n *     if not.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\n\nexport function registerBackend(name, factory) {\n  var priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  return ENGINE.registerBackend(name, factory, priority);\n}\n/**\r\n * Gets the current backend. If no backends have been initialized, this will\r\n * attempt to initialize the best backend. Will throw an error if the highest\r\n * priority backend has async initialization, in which case, you should call\r\n * 'await tf.ready()' before running other code.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\n\nexport function backend() {\n  return ENGINE.backend;\n}\n/**\r\n * Sets the global platform.\r\n *\r\n * @param platformName The name of this platform.\r\n * @param platform A platform implementation.\r\n */\n\nexport function setPlatform(platformName, platform) {\n  env().setPlatform(platformName, platform);\n}","map":{"version":3,"sources":["../src/globals.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAGH,SAAQ,MAAR,QAA2E,UAA3E;AACA,SAAQ,GAAR,QAAkB,eAAlB;AAGA,SAAQ,uBAAR,QAA8C,UAA9C;AAEA,SAAQ,qBAAR,QAAoC,eAApC;AAEA;;;;;AAKG;;AACH,OAAM,SAAU,cAAV,GAAwB;AAC5B,EAAA,GAAG,GAAG,GAAN,CAAU,MAAV,EAAkB,IAAlB;AACD;AAED;;;;;;;;;;;;;AAaG;;AACH,OAAM,SAAU,eAAV,GAAyB;AAC7B,EAAA,GAAG,GAAG,GAAN,CAAU,OAAV,EAAmB,IAAnB;AACD;AAED;;AACA,OAAM,SAAU,0BAAV,GAAoC;AACxC,EAAA,GAAG,GAAG,GAAN,CAAU,8BAAV,EAA0C,KAA1C;AACA,EAAA,OAAO,CAAC,IAAR;AACD;AAED;;AACA,OAAM,SAAU,eAAV,CAA0B,GAA1B,EAAqC;AACzC,MAAI,GAAG,GAAG,OAAN,CAAc,8BAAd,CAAJ,EAAmD;AACjD,IAAA,OAAO,CAAC,IAAR,CACI,GAAG,GAAG,6CAAN,GACA,kCAFJ;AAGD;AACF;AACD,uBAAuB,CAAC,eAAD,CAAvB;AAEA;;;;AAIG;;AACH,OAAM,SAAU,gBAAV,GAA0B;AAC9B,EAAA,MAAM,CAAC,gBAAP;AACD;AAED;;;;AAIG;;AACH,OAAM,SAAU,MAAV,GAAgB;AACpB,SAAO,MAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;AAoBG;;AACH,OAAM,SAAU,MAAV,GAAgB;AACpB,SAAO,MAAM,CAAC,MAAP,EAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4BG;;AACH,OAAM,SAAU,OAAV,CAAkB,CAAlB,EAAuE;AAE3E,SAAO,MAAM,CAAC,OAAP,CAAe,CAAf,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuCG;;AACH,OAAM,SAAU,IAAV,CACF,QADE,EAC2B,EAD3B,EAC0C;AAC9C,SAAO,MAAM,CAAC,IAAP,CAAY,QAAZ,EAAsB,EAAtB,CAAP;AACD;AAED;;;;;;;;;;AAUG;;AACH,OAAM,SAAU,OAAV,CAAkB,SAAlB,EAA4C;AAChD,MAAM,OAAO,GAAG,qBAAqB,CAAC,SAAD,CAArC;AACA,EAAA,OAAO,CAAC,OAAR,CAAgB,UAAA,MAAM;AAAA,WAAI,MAAM,CAAC,OAAP,EAAJ;AAAA,GAAtB;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+BG;;AACH,OAAM,SAAU,IAAV,CAAiC,MAAjC,EAA0C;AAC9C,SAAO,MAAM,CAAC,IAAP,CAAY,MAAZ,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;AAwBG;;AACH,OAAM,SAAU,IAAV,CAAe,CAAf,EAA4B;AAChC,SAAO,MAAM,CAAC,IAAP,CAAY,CAAZ,CAAP;AACD;AAED;;;;;;;;;;;;;;AAcG;;AACH,OAAM,SAAU,UAAV,CAAqB,WAArB,EAAwC;AAC5C,SAAO,MAAM,CAAC,UAAP,CAAkB,WAAlB,CAAP;AACD;AAED;;;;;;AAMG;;AACH,OAAM,SAAU,KAAV,GAAe;AACnB,SAAO,MAAM,CAAC,KAAP,EAAP;AACD;AAED;;;;;AAKG;;AACH,OAAM,SAAU,UAAV,GAAoB;AACxB,SAAO,MAAM,CAAC,WAAd;AACD;AAED;;;;AAIG;;AACH,OAAM,SAAU,aAAV,CAAwB,IAAxB,EAAoC;AACxC,EAAA,MAAM,CAAC,aAAP,CAAqB,IAArB;AACD;AAED;;;AAGG;;AACH,OAAM,SAAU,WAAV,CAAsB,IAAtB,EAAkC;AACtC,SAAO,MAAM,CAAC,WAAP,CAAmB,IAAnB,CAAP;AACD;AAED;;;;AAIG;;AACH,OAAM,SAAU,kBAAV,CAA6B,IAA7B,EAAyC;AAE7C,SAAO,MAAM,CAAC,kBAAP,CAA0B,IAA1B,CAAP;AACD;AAED;;;;;;;;;;;;;;AAcG;;AACH,OAAM,SAAU,eAAV,CACF,IADE,EACY,OADZ,EAEU;AAAA,MAAZ,QAAY,uEAAD,CAAC;AACd,SAAO,MAAM,CAAC,eAAP,CAAuB,IAAvB,EAA6B,OAA7B,EAAsC,QAAtC,CAAP;AACD;AAED;;;;;;;AAOG;;AACH,OAAM,SAAU,OAAV,GAAiB;AACrB,SAAO,MAAM,CAAC,OAAd;AACD;AAED;;;;;AAKG;;AACH,OAAM,SAAU,WAAV,CAAsB,YAAtB,EAA4C,QAA5C,EAA8D;AAClE,EAAA,GAAG,GAAG,WAAN,CAAkB,YAAlB,EAAgC,QAAhC;AACD","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from './engine';\r\nimport { env } from './environment';\r\nimport { setDeprecationWarningFn } from './tensor';\r\nimport { getTensorsInContainer } from './tensor_util';\r\n/**\r\n * Enables production mode which disables correctness checks in favor of\r\n * performance.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\r\nexport function enableProdMode() {\r\n    env().set('PROD', true);\r\n}\r\n/**\r\n * Enables debug mode which will log information about all executed kernels:\r\n * the elapsed time of the kernel execution, as well as the rank, shape, and\r\n * size of the output tensor.\r\n *\r\n * Debug mode will significantly slow down your application as it will\r\n * download the result of every operation to the CPU. This should not be used in\r\n * production. Debug mode does not affect the timing information of the kernel\r\n * execution as we do not measure download time in the kernel execution time.\r\n *\r\n * See also: `tf.profile`, `tf.memory`.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\r\nexport function enableDebugMode() {\r\n    env().set('DEBUG', true);\r\n}\r\n/** Globally disables deprecation warnings */\r\nexport function disableDeprecationWarnings() {\r\n    env().set('DEPRECATION_WARNINGS_ENABLED', false);\r\n    console.warn(`TensorFlow.js deprecation warnings have been disabled.`);\r\n}\r\n/** Warn users about deprecated functionality. */\r\nexport function deprecationWarn(msg) {\r\n    if (env().getBool('DEPRECATION_WARNINGS_ENABLED')) {\r\n        console.warn(msg + ' You can disable deprecation warnings with ' +\r\n            'tf.disableDeprecationWarnings().');\r\n    }\r\n}\r\nsetDeprecationWarningFn(deprecationWarn);\r\n/**\r\n * Dispose all variables kept in backend engine.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\r\nexport function disposeVariables() {\r\n    ENGINE.disposeVariables();\r\n}\r\n/**\r\n * It returns the global engine that keeps track of all tensors and backends.\r\n *\r\n * @doc {heading: 'Environment'}\r\n */\r\nexport function engine() {\r\n    return ENGINE;\r\n}\r\n/**\r\n * Returns memory info at the current time in the program. The result is an\r\n * object with the following properties:\r\n *\r\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\r\n * - `numTensors`: Number of unique tensors allocated.\r\n * - `numDataBuffers`: Number of unique data buffers allocated\r\n *   (undisposed) at this time, which is ≤ the number of tensors\r\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\r\n *   data buffer with `a`).\r\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\r\n *    `unreliable` is true.\r\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\r\n *    `unreliable` is true.\r\n *\r\n * WebGL Properties:\r\n * - `numBytesInGPU`: Number of bytes allocated (undisposed) in the GPU only at\r\n *     this time.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\r\nexport function memory() {\r\n    return ENGINE.memory();\r\n}\r\n/**\r\n * Executes the provided function `f()` and returns a promise that resolves\r\n * with information about the function's memory use:\r\n * - `newBytes`: the number of new bytes allocated\r\n * - `newTensors`: the number of new tensors created\r\n * - `peakBytes`: the peak number of bytes allocated\r\n * - `kernels`: an array of objects for each kernel involved that reports\r\n * their input and output shapes, number of bytes used, and number of new\r\n * tensors created.\r\n *\r\n * ```js\r\n * const profile = await tf.profile(() => {\r\n *   const x = tf.tensor1d([1, 2, 3]);\r\n *   let x2 = x.square();\r\n *   x2.dispose();\r\n *   x2 = x.square();\r\n *   x2.dispose();\r\n *   return x;\r\n * });\r\n *\r\n * console.log(`newBytes: ${profile.newBytes}`);\r\n * console.log(`newTensors: ${profile.newTensors}`);\r\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\r\n * k.totalBytesSnapshot)}`);\r\n * ```\r\n *\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Profile'}\r\n */\r\nexport function profile(f) {\r\n    return ENGINE.profile(f);\r\n}\r\n/**\r\n * Executes the provided function `fn` and after it is executed, cleans up all\r\n * intermediate tensors allocated by `fn` except those returned by `fn`.\r\n * `fn` must not return a Promise (async functions not allowed). The returned\r\n * result can be a complex object.\r\n *\r\n * Using this method helps avoid memory leaks. In general, wrap calls to\r\n * operations in `tf.tidy` for automatic memory cleanup.\r\n *\r\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\r\n * dispose variables, please use `tf.disposeVariables` or call dispose()\r\n * directly on variables.\r\n *\r\n * ```js\r\n * // y = 2 ^ 2 + 1\r\n * const y = tf.tidy(() => {\r\n *   // a, b, and one will be cleaned up when the tidy ends.\r\n *   const one = tf.scalar(1);\r\n *   const a = tf.scalar(2);\r\n *   const b = a.square();\r\n *\r\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\r\n *\r\n *   // The value returned inside the tidy function will return\r\n *   // through the tidy, in this case to the variable y.\r\n *   return b.add(one);\r\n * });\r\n *\r\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\r\n * y.print();\r\n * ```\r\n *\r\n * @param nameOrFn The name of the closure, or the function to execute.\r\n *     If a name is provided, the 2nd argument should be the function.\r\n *     If debug mode is on, the timing and the memory usage of the function\r\n *     will be tracked and displayed on the console using the provided name.\r\n * @param fn The function to execute.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\r\nexport function tidy(nameOrFn, fn) {\r\n    return ENGINE.tidy(nameOrFn, fn);\r\n}\r\n/**\r\n * Disposes any `tf.Tensor`s found within the provided object.\r\n *\r\n * @param container an object that may be a `tf.Tensor` or may directly\r\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\r\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\r\n *     happens. In general it is safe to pass any object here, except that\r\n *     `Promise`s are not supported.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\r\nexport function dispose(container) {\r\n    const tensors = getTensorsInContainer(container);\r\n    tensors.forEach(tensor => tensor.dispose());\r\n}\r\n/**\r\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\r\n * automatically.\r\n *\r\n * ```js\r\n * let b;\r\n * const y = tf.tidy(() => {\r\n *   const one = tf.scalar(1);\r\n *   const a = tf.scalar(2);\r\n *\r\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\r\n *   // when the tidy ends.\r\n *   b = tf.keep(a.square());\r\n *\r\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\r\n *\r\n *   // The value returned inside the tidy function will return\r\n *   // through the tidy, in this case to the variable y.\r\n *   return b.add(one);\r\n * });\r\n *\r\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\r\n * console.log('y:');\r\n * y.print();\r\n * console.log('b:');\r\n * b.print();\r\n * ```\r\n *\r\n * @param result The tensor to keep from being disposed.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Memory'}\r\n */\r\nexport function keep(result) {\r\n    return ENGINE.keep(result);\r\n}\r\n/**\r\n * Executes `f()` and returns a promise that resolves with timing\r\n * information.\r\n *\r\n * The result is an object with the following properties:\r\n *\r\n * - `wallMs`: Wall execution time.\r\n * - `kernelMs`: Kernel execution time, ignoring data transfer. If using the\r\n * WebGL backend and the query timer extension is not available, this will\r\n * return an error object.\r\n * - On `WebGL` The following additional properties exist:\r\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\r\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\r\n *\r\n * ```js\r\n * const x = tf.randomNormal([20, 20]);\r\n * const time = await tf.time(() => x.matMul(x));\r\n *\r\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\r\n * ```\r\n *\r\n * @param f The function to execute and time.\r\n *\r\n * @doc {heading: 'Performance', subheading: 'Timing'}\r\n */\r\nexport function time(f) {\r\n    return ENGINE.time(f);\r\n}\r\n/**\r\n * Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and\r\n * executing operations on those tensors. Returns a promise that resolves\r\n * to a boolean if the backend initialization was successful.\r\n *\r\n * Note this disposes the current backend, if any, as well as any tensors\r\n * associated with it. A new backend is initialized, even if it is of the\r\n * same type as the previous one.\r\n *\r\n * @param backendName The name of the backend. Currently supports\r\n *     `'webgl'|'cpu'` in the browser, `'tensorflow'` under node.js\r\n *     (requires tfjs-node), and `'wasm'` (requires tfjs-backend-wasm).\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\r\nexport function setBackend(backendName) {\r\n    return ENGINE.setBackend(backendName);\r\n}\r\n/**\r\n * Returns a promise that resolves when the currently selected backend (or the\r\n * highest priority one) has initialized. Await this promise when you are using\r\n * a backend that has async initialization.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\r\nexport function ready() {\r\n    return ENGINE.ready();\r\n}\r\n/**\r\n * Returns the current backend name (cpu, webgl, etc). The backend is\r\n * responsible for creating tensors and executing operations on those tensors.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\r\nexport function getBackend() {\r\n    return ENGINE.backendName;\r\n}\r\n/**\r\n * Removes a backend and the registered factory.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\r\nexport function removeBackend(name) {\r\n    ENGINE.removeBackend(name);\r\n}\r\n/**\r\n * Finds the backend registered under the provided name. Returns null if the\r\n * name is not in the registry, or the registration hasn't finished yet.\r\n */\r\nexport function findBackend(name) {\r\n    return ENGINE.findBackend(name);\r\n}\r\n/**\r\n * Finds the backend factory registered under the provided name. Returns a\r\n * function that produces a new backend when called. Returns null if the name\r\n * is not in the registry.\r\n */\r\nexport function findBackendFactory(name) {\r\n    return ENGINE.findBackendFactory(name);\r\n}\r\n/**\r\n * Registers a global backend. The registration should happen when importing\r\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\r\n * modular builds (e.g. custom tfjs bundle with only webgl support).\r\n *\r\n * @param factory The backend factory function. When called, it should\r\n * return a backend instance, or a promise of an instance.\r\n * @param priority The priority of the backend (higher = more important).\r\n *     In case multiple backends are registered, the priority is used to find\r\n *     the best backend. Defaults to 1.\r\n * @return False if there is already a registered backend under this name, true\r\n *     if not.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\r\nexport function registerBackend(name, factory, priority = 1) {\r\n    return ENGINE.registerBackend(name, factory, priority);\r\n}\r\n/**\r\n * Gets the current backend. If no backends have been initialized, this will\r\n * attempt to initialize the best backend. Will throw an error if the highest\r\n * priority backend has async initialization, in which case, you should call\r\n * 'await tf.ready()' before running other code.\r\n *\r\n * @doc {heading: 'Backends'}\r\n */\r\nexport function backend() {\r\n    return ENGINE.backend;\r\n}\r\n/**\r\n * Sets the global platform.\r\n *\r\n * @param platformName The name of this platform.\r\n * @param platform A platform implementation.\r\n */\r\nexport function setPlatform(platformName, platform) {\r\n    env().setPlatform(platformName, platform);\r\n}\r\n//# sourceMappingURL=globals.js.map"]},"metadata":{},"sourceType":"module"}