{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { Relu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\nimport { cast } from './cast';\n/**\r\n * Computes rectified linear element-wise: `max(x, 0)`.\r\n *\r\n * ```js\r\n * const x = tf.tensor1d([-1, 2, -3, 4]);\r\n *\r\n * x.relu().print();  // or tf.relu(x)\r\n * ```\r\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\r\n *     `int32'.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Basic math'}\r\n */\n\nfunction relu_(x) {\n  var $x = convertToTensor(x, 'x', 'relu');\n\n  var forward = function forward(backend, save) {\n    save([$x]);\n\n    if ($x.dtype === 'bool') {\n      return cast($x, 'int32');\n    }\n\n    return backend.relu($x);\n  };\n\n  var inputs = {\n    x: $x\n  };\n  return ENGINE.runKernelFunc(forward, inputs, null\n  /* grad */\n  , Relu);\n}\n\nexport var relu = op({\n  relu_: relu_\n});","map":{"version":3,"sources":["../../src/ops/relu.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAkC,WAAlC;AACA,SAAQ,IAAR,QAA+B,iBAA/B;AAGA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAS,IAAT,QAAqB,QAArB;AAEA;;;;;;;;;;;;AAYG;;AACH,SAAS,KAAT,CAAiC,CAAjC,EAAgD;AAC9C,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,MAAT,CAA1B;;AAEA,MAAM,OAAO,GAAwB,SAA/B,OAA+B,CAAC,OAAD,EAAU,IAAV,EAAkB;AACrD,IAAA,IAAI,CAAC,CAAC,EAAD,CAAD,CAAJ;;AAEA,QAAI,EAAE,CAAC,KAAH,KAAa,MAAjB,EAAyB;AACvB,aAAO,IAAI,CAAC,EAAD,EAAK,OAAL,CAAX;AACD;;AAED,WAAO,OAAO,CAAC,IAAR,CAAa,EAAb,CAAP;AACD,GARD;;AAUA,MAAM,MAAM,GAAe;AAAC,IAAA,CAAC,EAAE;AAAJ,GAA3B;AAEA,SAAO,MAAM,CAAC,aAAP,CACI,OADJ,EACa,MADb,EAC6C;AAAK;AADlD,IAC8D,IAD9D,CAAP;AAGD;;AAED,OAAO,IAAM,IAAI,GAAG,EAAE,CAAC;AAAC,EAAA,KAAK,EAAL;AAAD,CAAD,CAAf","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { Relu } from '../kernel_names';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport { op } from './operation';\r\nimport { cast } from './cast';\r\n/**\r\n * Computes rectified linear element-wise: `max(x, 0)`.\r\n *\r\n * ```js\r\n * const x = tf.tensor1d([-1, 2, -3, 4]);\r\n *\r\n * x.relu().print();  // or tf.relu(x)\r\n * ```\r\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\r\n *     `int32'.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Basic math'}\r\n */\r\nfunction relu_(x) {\r\n    const $x = convertToTensor(x, 'x', 'relu');\r\n    const forward = (backend, save) => {\r\n        save([$x]);\r\n        if ($x.dtype === 'bool') {\r\n            return cast($x, 'int32');\r\n        }\r\n        return backend.relu($x);\r\n    };\r\n    const inputs = { x: $x };\r\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Relu);\r\n}\r\nexport const relu = op({ relu_ });\r\n//# sourceMappingURL=relu.js.map"]},"metadata":{},"sourceType":"module"}