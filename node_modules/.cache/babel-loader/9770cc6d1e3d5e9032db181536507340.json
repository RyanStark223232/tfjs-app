{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\r\n * @deprecated\r\n * Adds two `tf.Tensor`s element-wise, A + B.\r\n *\r\n * Inputs must be the same shape. For broadcasting support, use add() instead.\r\n *\r\n * @param a The first Tensor to add element-wise.\r\n * @param b The second Tensor to add element-wise.\r\n */\n\nfunction addStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'addStrict');\n  var $b = convertToTensor(b, 'b', 'addStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n  return add($a, $b);\n}\n/**\r\n * @deprecated\r\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\r\n * be the same shape.\r\n *\r\n * For broadcasting support, use `tf.sub` instead.\r\n *\r\n * @param a The first Tensor to subtract element-wise.\r\n * @param b The second Tensor to subtract element-wise.\r\n */\n\n\nfunction subStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'subStrict');\n  var $b = convertToTensor(b, 'b', 'subStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n  return sub($a, $b);\n}\n/**\r\n * @deprecated\r\n * Computes the power of one `tf.Tensor` to another. Inputs must\r\n * be the same shape.\r\n *\r\n * For broadcasting support, use `tf.pow` instead.\r\n *\r\n * @param base The base tensor to pow element-wise.\r\n * @param exp The exponent tensor to pow element-wise.\r\n */\n\n\nfunction powStrict_(base, exp) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n  return pow(base, exp);\n}\n/**\r\n * @deprecated\r\n * Multiplies two `tf.Tensor`s element-wise, A * B.\r\n *\r\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\r\n *\r\n * @param a The first tensor to multiply.\r\n * @param b The first tensor to multiply. Must have the same\r\n *    dtype as `a`.\r\n */\n\n\nfunction mulStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'mul');\n  var $b = convertToTensor(b, 'b', 'mul');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n  return mul($a, $b);\n}\n/**\r\n * @deprecated\r\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\r\n * be the same shape.\r\n *\r\n * @param a The first tensor as the numerator for element-wise division.\r\n * @param b The second tensor as the denominator for element-wise division.\r\n */\n\n\nfunction divStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'div');\n  var $b = convertToTensor(b, 'b', 'div');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n  return div($a, $b);\n}\n/**\r\n * @deprecated\r\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\r\n * be the same shape. For broadcasting support, use mod().\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same dtype as `a`.\r\n */\n\n\nfunction modStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'modStrict');\n  var $b = convertToTensor(b, 'b', 'modStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n  return mod($a, $b);\n}\n/**\r\n * @deprecated\r\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\r\n * be the same shape. For broadcasting support, use minimum().\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same dtype as `a`.\r\n */\n\n\nfunction minimumStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'minimumStrict');\n  var $b = convertToTensor(b, 'b', 'minimumStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n  return minimum($a, $b);\n}\n/**\r\n * @deprecated\r\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\r\n * be the same shape. For broadcasting support, use maximum().\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same dtype as `a`.\r\n */\n\n\nfunction maximumStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'maximumStrict');\n  var $b = convertToTensor(b, 'b', 'maximumStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n  return maximum($a, $b);\n}\n/**\r\n * @deprecated\r\n * Returns (a - b) * (a - b) element-wise.\r\n *\r\n * Inputs must be the same shape. For broadcasting support, use\r\n * `tf.squaredDifference` instead.\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same type as `a`.\r\n */\n\n\nfunction squaredDifferenceStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  var $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n  var $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n  return squaredDifference($a, $b);\n}\n\nexport var addStrict = op({\n  addStrict_: addStrict_\n});\nexport var divStrict = op({\n  divStrict_: divStrict_\n});\nexport var maximumStrict = op({\n  maximumStrict_: maximumStrict_\n});\nexport var minimumStrict = op({\n  minimumStrict_: minimumStrict_\n});\nexport var modStrict = op({\n  modStrict_: modStrict_\n});\nexport var mulStrict = op({\n  mulStrict_: mulStrict_\n});\nexport var powStrict = op({\n  powStrict_: powStrict_\n});\nexport var squaredDifferenceStrict = op({\n  squaredDifferenceStrict_: squaredDifferenceStrict_\n});\nexport var subStrict = op({\n  subStrict_: subStrict_\n});","map":{"version":3,"sources":["../../src/ops/binary_ops.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,eAAR,QAA8B,YAA9B;AAEA,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,OAAO,KAAK,IAAZ,MAAsB,SAAtB;AAEA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,iBAAR,QAAgC,sBAAhC;AACA,SAAQ,GAAR,QAAkB,OAAlB;AAEA;;;;;;;;AAQG;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAGA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,sBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,sBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,UAAT,CAAsC,IAAtC,EAA+C,GAA/C,EAA0D;AACxD,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,EAAA,IAAI,CAAC,iBAAL,CAAuB,IAAI,CAAC,KAA5B,EAAmC,GAAG,CAAC,KAAvC,EAA8C,sBAA9C;AACA,SAAO,GAAG,CAAC,IAAD,EAAO,GAAP,CAAV;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,2BAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,yBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,sBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,cAAT,CAA0C,CAA1C,EAA2D,CAA3D,EAA0E;AACxE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,0BAA3C;AACA,SAAO,OAAO,CAAC,EAAD,EAAK,EAAL,CAAd;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,cAAT,CAA0C,CAA1C,EAA2D,CAA3D,EAA0E;AACxE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,0BAA3C;AACA,SAAO,OAAO,CAAC,EAAD,EAAK,EAAL,CAAd;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,wBAAT,CACI,CADJ,EACqB,CADrB,EACoC;AAClC,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAGA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,yBAAT,CAA1B;AACA,MAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,yBAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CACI,EAAE,CAAC,KADP,EACc,EAAE,CAAC,KADjB,EACwB,oCADxB;AAEA,SAAO,iBAAiB,CAAC,EAAD,EAAK,EAAL,CAAxB;AACD;;AAED,OAAO,IAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA,UAAU,EAAV;AAAD,CAAD,CAApB;AACP,OAAO,IAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA,UAAU,EAAV;AAAD,CAAD,CAApB;AACP,OAAO,IAAM,aAAa,GAAG,EAAE,CAAC;AAAC,EAAA,cAAc,EAAd;AAAD,CAAD,CAAxB;AACP,OAAO,IAAM,aAAa,GAAG,EAAE,CAAC;AAAC,EAAA,cAAc,EAAd;AAAD,CAAD,CAAxB;AACP,OAAO,IAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA,UAAU,EAAV;AAAD,CAAD,CAApB;AACP,OAAO,IAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA,UAAU,EAAV;AAAD,CAAD,CAApB;AACP,OAAO,IAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA,UAAU,EAAV;AAAD,CAAD,CAApB;AACP,OAAO,IAAM,uBAAuB,GAAG,EAAE,CAAC;AAAC,EAAA,wBAAwB,EAAxB;AAAD,CAAD,CAAlC;AACP,OAAO,IAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA,UAAU,EAAV;AAAD,CAAD,CAApB","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { deprecationWarn } from '../globals';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport * as util from '../util';\r\nimport { add } from './add';\r\nimport { div } from './div';\r\nimport { maximum } from './maximum';\r\nimport { minimum } from './minimum';\r\nimport { mod } from './mod';\r\nimport { mul } from './mul';\r\nimport { op } from './operation';\r\nimport { pow } from './pow';\r\nimport { squaredDifference } from './squared_difference';\r\nimport { sub } from './sub';\r\n/**\r\n * @deprecated\r\n * Adds two `tf.Tensor`s element-wise, A + B.\r\n *\r\n * Inputs must be the same shape. For broadcasting support, use add() instead.\r\n *\r\n * @param a The first Tensor to add element-wise.\r\n * @param b The second Tensor to add element-wise.\r\n */\r\nfunction addStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'addStrict');\r\n    const $b = convertToTensor(b, 'b', 'addStrict');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\r\n    return add($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\r\n * be the same shape.\r\n *\r\n * For broadcasting support, use `tf.sub` instead.\r\n *\r\n * @param a The first Tensor to subtract element-wise.\r\n * @param b The second Tensor to subtract element-wise.\r\n */\r\nfunction subStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'subStrict');\r\n    const $b = convertToTensor(b, 'b', 'subStrict');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\r\n    return sub($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Computes the power of one `tf.Tensor` to another. Inputs must\r\n * be the same shape.\r\n *\r\n * For broadcasting support, use `tf.pow` instead.\r\n *\r\n * @param base The base tensor to pow element-wise.\r\n * @param exp The exponent tensor to pow element-wise.\r\n */\r\nfunction powStrict_(base, exp) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\r\n    return pow(base, exp);\r\n}\r\n/**\r\n * @deprecated\r\n * Multiplies two `tf.Tensor`s element-wise, A * B.\r\n *\r\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\r\n *\r\n * @param a The first tensor to multiply.\r\n * @param b The first tensor to multiply. Must have the same\r\n *    dtype as `a`.\r\n */\r\nfunction mulStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'mul');\r\n    const $b = convertToTensor(b, 'b', 'mul');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\r\n    return mul($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\r\n * be the same shape.\r\n *\r\n * @param a The first tensor as the numerator for element-wise division.\r\n * @param b The second tensor as the denominator for element-wise division.\r\n */\r\nfunction divStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'div');\r\n    const $b = convertToTensor(b, 'b', 'div');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\r\n    return div($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\r\n * be the same shape. For broadcasting support, use mod().\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same dtype as `a`.\r\n */\r\nfunction modStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'modStrict');\r\n    const $b = convertToTensor(b, 'b', 'modStrict');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\r\n    return mod($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\r\n * be the same shape. For broadcasting support, use minimum().\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same dtype as `a`.\r\n */\r\nfunction minimumStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'minimumStrict');\r\n    const $b = convertToTensor(b, 'b', 'minimumStrict');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\r\n    return minimum($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\r\n * be the same shape. For broadcasting support, use maximum().\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same dtype as `a`.\r\n */\r\nfunction maximumStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'maximumStrict');\r\n    const $b = convertToTensor(b, 'b', 'maximumStrict');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\r\n    return maximum($a, $b);\r\n}\r\n/**\r\n * @deprecated\r\n * Returns (a - b) * (a - b) element-wise.\r\n *\r\n * Inputs must be the same shape. For broadcasting support, use\r\n * `tf.squaredDifference` instead.\r\n *\r\n * @param a The first tensor.\r\n * @param b The second tensor. Must have the same type as `a`.\r\n */\r\nfunction squaredDifferenceStrict_(a, b) {\r\n    deprecationWarn('strict variants of ops have been deprecated ' +\r\n        'and will be removed in future');\r\n    const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\r\n    const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\r\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\r\n    return squaredDifference($a, $b);\r\n}\r\nexport const addStrict = op({ addStrict_ });\r\nexport const divStrict = op({ divStrict_ });\r\nexport const maximumStrict = op({ maximumStrict_ });\r\nexport const minimumStrict = op({ minimumStrict_ });\r\nexport const modStrict = op({ modStrict_ });\r\nexport const mulStrict = op({ mulStrict_ });\r\nexport const powStrict = op({ powStrict_ });\r\nexport const squaredDifferenceStrict = op({ squaredDifferenceStrict_ });\r\nexport const subStrict = op({ subStrict_ });\r\n//# sourceMappingURL=binary_ops.js.map"]},"metadata":{},"sourceType":"module"}