{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { customGrad } from '../gradients';\nimport { Mean } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam, sizeFromShape } from '../util';\nimport { computeOutAndReduceShapes } from './axis_util';\nimport { cast } from './cast';\nimport { div } from './div';\nimport { mul } from './mul';\nimport { ones } from './ones';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { scalar } from './scalar';\nimport { sum } from './sum';\n/**\r\n * Computes the mean of elements across dimensions of a `tf.Tensor`.\r\n *\r\n * Reduces `x` along the dimensions given in `axis`. Unless `keepDims` is\r\n * true, the rank of the `tf.Tensor` is reduced by 1 for each entry in `axis`.\r\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\r\n * If `axis` has no entries, all dimensions are reduced, and a `tf.Tensor` with\r\n * a single element is returned.\r\n *\r\n * ```js\r\n * const x = tf.tensor1d([1, 2, 3]);\r\n *\r\n * x.mean().print();  // or tf.mean(a)\r\n * ```\r\n *\r\n * ```js\r\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\r\n *\r\n * const axis = 1;\r\n * x.mean(axis).print();  // or tf.mean(x, axis)\r\n * ```\r\n *\r\n * @param x The input tensor.\r\n * @param axis The dimension(s) to reduce. By default it reduces\r\n *     all dimensions.\r\n * @param keepDims If true, retains reduced dimensions with size 1.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Reduction'}\r\n */\n\nfunction mean_(x, axis = null, keepDims = false) {\n  const $x = convertToTensor(x, 'x', 'mean');\n  const axes = parseAxisParam(axis, $x.shape);\n  const shapes = computeOutAndReduceShapes($x.shape, axes);\n  const reduceShape = shapes[1];\n  const reduceSize = sizeFromShape(reduceShape);\n  const inputs = {\n    x: $x\n  };\n  const attrs = {\n    axis,\n    keepDims\n  };\n\n  const forward = () => {\n    const reduceSizeScalar = scalar(reduceSize); // Cast if needed.\n\n    const xReduce = reduceSizeScalar.dtype === $x.dtype ? $x : cast($x, reduceSizeScalar.dtype);\n    const res = div(xReduce, reduceSizeScalar);\n    return sum(res, axis, keepDims);\n  }; // Use a custom gradient to bypass 2 gradient backprops since mean is used\n  // extremely often.\n\n\n  const customOp = customGrad(x => {\n    const value = ENGINE.runKernelFunc(forward, inputs, null\n    /* grad */\n    , Mean, attrs);\n\n    const gradFunc = dy => {\n      const expandedDyShape = x.shape.slice();\n      axes.forEach(axis => {\n        expandedDyShape[axis] = 1;\n      });\n      const expandedDy = reshape(dy, expandedDyShape);\n      const derX = div(mul(expandedDy, ones(x.shape, 'float32')), reduceSize);\n      return derX;\n    };\n\n    return {\n      value,\n      gradFunc\n    };\n  });\n  return customOp($x);\n}\n\nexport const mean = op({\n  mean_\n});","map":{"version":3,"sources":["../../src/ops/mean.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAkC,WAAlC;AACA,SAAQ,UAAR,QAAyB,cAAzB;AACA,SAAQ,IAAR,QAA0C,iBAA1C;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,SAAQ,cAAR,EAAwB,aAAxB,QAA4C,SAA5C;AAEA,SAAQ,yBAAR,QAAwC,aAAxC;AACA,SAAQ,IAAR,QAAmB,QAAnB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,IAAR,QAAmB,QAAnB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,MAAR,QAAqB,UAArB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4BG;;AACH,SAAS,KAAT,CACI,CADJ,EAC0B,IAAA,GAAwB,IADlD,EACwD,QAAQ,GAAG,KADnE,EACwE;AACtE,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,MAAT,CAA1B;AAEA,QAAM,IAAI,GAAG,cAAc,CAAC,IAAD,EAAO,EAAE,CAAC,KAAV,CAA3B;AACA,QAAM,MAAM,GAAG,yBAAyB,CAAC,EAAE,CAAC,KAAJ,EAAW,IAAX,CAAxC;AACA,QAAM,WAAW,GAAG,MAAM,CAAC,CAAD,CAA1B;AACA,QAAM,UAAU,GAAG,aAAa,CAAC,WAAD,CAAhC;AAEA,QAAM,MAAM,GAAe;AAAC,IAAA,CAAC,EAAE;AAAJ,GAA3B;AACA,QAAM,KAAK,GAAc;AAAC,IAAA,IAAD;AAAO,IAAA;AAAP,GAAzB;;AACA,QAAM,OAAO,GAAwB,MAAK;AACxC,UAAM,gBAAgB,GAAG,MAAM,CAAC,UAAD,CAA/B,CADwC,CAExC;;AACA,UAAM,OAAO,GAAG,gBAAgB,CAAC,KAAjB,KAA2B,EAAE,CAAC,KAA9B,GACZ,EADY,GAEZ,IAAI,CAAC,EAAD,EAAK,gBAAgB,CAAC,KAAtB,CAFR;AAGA,UAAM,GAAG,GAAG,GAAG,CAAC,OAAD,EAAU,gBAAV,CAAf;AACA,WAAO,GAAG,CAAC,GAAD,EAAM,IAAN,EAAY,QAAZ,CAAV;AACD,GARD,CAVsE,CAoBtE;AACA;;;AACA,QAAM,QAAQ,GAAG,UAAU,CAAE,CAAD,IAAc;AACxC,UAAM,KAAK,GAAG,MAAM,CAAC,aAAP,CACV,OADU,EACD,MADC,EAC+B;AAAK;AADpC,MACgD,IADhD,EAEV,KAFU,CAAd;;AAIA,UAAM,QAAQ,GAAI,EAAD,IAAe;AAC9B,YAAM,eAAe,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,EAAxB;AACA,MAAA,IAAI,CAAC,OAAL,CAAa,IAAI,IAAG;AAClB,QAAA,eAAe,CAAC,IAAD,CAAf,GAAwB,CAAxB;AACD,OAFD;AAGA,YAAM,UAAU,GAAG,OAAO,CAAC,EAAD,EAAK,eAAL,CAA1B;AACA,YAAM,IAAI,GAAG,GAAG,CAAC,GAAG,CAAC,UAAD,EAAa,IAAI,CAAC,CAAC,CAAC,KAAH,EAAU,SAAV,CAAjB,CAAJ,EAA4C,UAA5C,CAAhB;AACA,aAAO,IAAP;AACD,KARD;;AASA,WAAO;AAAC,MAAA,KAAD;AAAQ,MAAA;AAAR,KAAP;AACD,GAf0B,CAA3B;AAiBA,SAAO,QAAQ,CAAC,EAAD,CAAf;AACD;;AAED,OAAO,MAAM,IAAI,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAf","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { customGrad } from '../gradients';\r\nimport { Mean } from '../kernel_names';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport { parseAxisParam, sizeFromShape } from '../util';\r\nimport { computeOutAndReduceShapes } from './axis_util';\r\nimport { cast } from './cast';\r\nimport { div } from './div';\r\nimport { mul } from './mul';\r\nimport { ones } from './ones';\r\nimport { op } from './operation';\r\nimport { reshape } from './reshape';\r\nimport { scalar } from './scalar';\r\nimport { sum } from './sum';\r\n/**\r\n * Computes the mean of elements across dimensions of a `tf.Tensor`.\r\n *\r\n * Reduces `x` along the dimensions given in `axis`. Unless `keepDims` is\r\n * true, the rank of the `tf.Tensor` is reduced by 1 for each entry in `axis`.\r\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\r\n * If `axis` has no entries, all dimensions are reduced, and a `tf.Tensor` with\r\n * a single element is returned.\r\n *\r\n * ```js\r\n * const x = tf.tensor1d([1, 2, 3]);\r\n *\r\n * x.mean().print();  // or tf.mean(a)\r\n * ```\r\n *\r\n * ```js\r\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\r\n *\r\n * const axis = 1;\r\n * x.mean(axis).print();  // or tf.mean(x, axis)\r\n * ```\r\n *\r\n * @param x The input tensor.\r\n * @param axis The dimension(s) to reduce. By default it reduces\r\n *     all dimensions.\r\n * @param keepDims If true, retains reduced dimensions with size 1.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Reduction'}\r\n */\r\nfunction mean_(x, axis = null, keepDims = false) {\r\n    const $x = convertToTensor(x, 'x', 'mean');\r\n    const axes = parseAxisParam(axis, $x.shape);\r\n    const shapes = computeOutAndReduceShapes($x.shape, axes);\r\n    const reduceShape = shapes[1];\r\n    const reduceSize = sizeFromShape(reduceShape);\r\n    const inputs = { x: $x };\r\n    const attrs = { axis, keepDims };\r\n    const forward = () => {\r\n        const reduceSizeScalar = scalar(reduceSize);\r\n        // Cast if needed.\r\n        const xReduce = reduceSizeScalar.dtype === $x.dtype ?\r\n            $x :\r\n            cast($x, reduceSizeScalar.dtype);\r\n        const res = div(xReduce, reduceSizeScalar);\r\n        return sum(res, axis, keepDims);\r\n    };\r\n    // Use a custom gradient to bypass 2 gradient backprops since mean is used\r\n    // extremely often.\r\n    const customOp = customGrad((x) => {\r\n        const value = ENGINE.runKernelFunc(forward, inputs, null /* grad */, Mean, attrs);\r\n        const gradFunc = (dy) => {\r\n            const expandedDyShape = x.shape.slice();\r\n            axes.forEach(axis => {\r\n                expandedDyShape[axis] = 1;\r\n            });\r\n            const expandedDy = reshape(dy, expandedDyShape);\r\n            const derX = div(mul(expandedDy, ones(x.shape, 'float32')), reduceSize);\r\n            return derX;\r\n        };\r\n        return { value, gradFunc };\r\n    });\r\n    return customOp($x);\r\n}\r\nexport const mean = op({ mean_ });\r\n//# sourceMappingURL=mean.js.map"]},"metadata":{},"sourceType":"module"}