{"ast":null,"code":"import _slicedToArray from \"C:/Users/wongh/Documents/GitHub/tfjs-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { Relu } from '../kernel_names';\nimport { cast } from '../ops/cast';\nimport { mul } from '../ops/mul';\nimport { step } from '../ops/step';\nexport var reluGradConfig = {\n  kernelName: Relu,\n  inputsToSave: ['x'],\n  gradFunc: function gradFunc(dy, saved) {\n    var _saved = _slicedToArray(saved, 1),\n        _x = _saved[0];\n\n    return {\n      x: function x() {\n        return mul(dy, cast(step(_x), 'float32'));\n      }\n    };\n  }\n};","map":{"version":3,"sources":["../../src/gradients/Relu_grad.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AACH,SAAQ,IAAR,QAAmB,iBAAnB;AAEA,SAAQ,IAAR,QAAmB,aAAnB;AACA,SAAQ,GAAR,QAAkB,YAAlB;AACA,SAAQ,IAAR,QAAmB,aAAnB;AAGA,OAAO,IAAM,cAAc,GAAe;AACxC,EAAA,UAAU,EAAE,IAD4B;AAExC,EAAA,YAAY,EAAE,CAAC,GAAD,CAF0B;AAGxC,EAAA,QAAQ,EAAE,kBAAC,EAAD,EAAa,KAAb,EAAgC;AAAA,gCAC5B,KAD4B;AAAA,QACjC,EADiC;;AAExC,WAAO;AAAC,MAAA,CAAC,EAAE;AAAA,eAAM,GAAG,CAAC,EAAD,EAAK,IAAI,CAAC,IAAI,CAAC,EAAD,CAAL,EAAU,SAAV,CAAT,CAAT;AAAA;AAAJ,KAAP;AACD;AANuC,CAAnC","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { Relu } from '../kernel_names';\r\nimport { cast } from '../ops/cast';\r\nimport { mul } from '../ops/mul';\r\nimport { step } from '../ops/step';\r\nexport const reluGradConfig = {\r\n    kernelName: Relu,\r\n    inputsToSave: ['x'],\r\n    gradFunc: (dy, saved) => {\r\n        const [x] = saved;\r\n        return { x: () => mul(dy, cast(step(x), 'float32')) };\r\n    }\r\n};\r\n//# sourceMappingURL=Relu_grad.js.map"]},"metadata":{},"sourceType":"module"}