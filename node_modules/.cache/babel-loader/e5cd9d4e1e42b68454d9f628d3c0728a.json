{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { LogSoftmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { exp } from './exp';\nimport { log } from './log';\nimport { max } from './max';\nimport { op } from './operation';\nimport { sub } from './sub';\nimport { sum } from './sum';\n/**\r\n * Computes the log softmax.\r\n *\r\n * ```js\r\n * const a = tf.tensor1d([1, 2, 3]);\r\n *\r\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\r\n * ```\r\n *\r\n * ```js\r\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\r\n *\r\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\r\n * ```\r\n *\r\n * @param logits The logits array.\r\n * @param axis The dimension softmax would be performed on. Defaults to `-1`\r\n *     which indicates the last dimension.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Normalization'}\r\n */\n\nfunction logSoftmax_(logits) {\n  var axis = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n  var $logits = convertToTensor(logits, 'logits', 'logSoftmax');\n\n  if (axis === -1) {\n    axis = $logits.rank - 1;\n  }\n\n  if (axis !== $logits.rank - 1) {\n    throw Error('Log Softmax along a non-last dimension is not yet supported. ' + \"Logits was rank \".concat($logits.rank, \" and axis was \").concat(axis));\n  }\n\n  var forward = function forward(backend, save) {\n    var keepDims = true;\n    var xMax = max(logits, axis, true);\n    var shifted = sub(logits, xMax);\n    var value = sub(cast(shifted, 'float32'), log(sum(exp(shifted), axis, keepDims)));\n    save([value]);\n    return value;\n  };\n\n  var inputs = {\n    logits: $logits\n  };\n  var attrs = {\n    axis: axis\n  };\n  return ENGINE.runKernelFunc(forward, inputs, null\n  /* grad */\n  , LogSoftmax, attrs);\n}\n\nexport var logSoftmax = op({\n  logSoftmax_: logSoftmax_\n});","map":{"version":3,"sources":["../../src/ops/log_softmax.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAkC,WAAlC;AACA,SAAQ,UAAR,QAA4D,iBAA5D;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,IAAR,QAAmB,QAAnB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AAEA;;;;;;;;;;;;;;;;;;;;AAoBG;;AACH,SAAS,WAAT,CAAuC,MAAvC,EAAsE;AAAA,MAAT,IAAS,uEAAF,CAAC,CAAC;AACpE,MAAM,OAAO,GAAG,eAAe,CAAC,MAAD,EAAS,QAAT,EAAmB,YAAnB,CAA/B;;AAEA,MAAI,IAAI,KAAK,CAAC,CAAd,EAAiB;AACf,IAAA,IAAI,GAAG,OAAO,CAAC,IAAR,GAAe,CAAtB;AACD;;AACD,MAAI,IAAI,KAAK,OAAO,CAAC,IAAR,GAAe,CAA5B,EAA+B;AAC7B,UAAM,KAAK,CACP,4FACmB,OAAO,CAAC,IAD3B,2BACgD,IADhD,CADO,CAAX;AAGD;;AAED,MAAM,OAAO,GAAwB,SAA/B,OAA+B,CAAC,OAAD,EAAU,IAAV,EAAkB;AACrD,QAAM,QAAQ,GAAG,IAAjB;AACA,QAAM,IAAI,GAAG,GAAG,CAAC,MAAD,EAAS,IAAT,EAAe,IAAf,CAAhB;AACA,QAAM,OAAO,GAAG,GAAG,CAAC,MAAD,EAAS,IAAT,CAAnB;AACA,QAAM,KAAK,GACP,GAAG,CAAC,IAAI,CAAC,OAAD,EAAU,SAAV,CAAL,EAA2B,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,OAAD,CAAJ,EAAe,IAAf,EAAqB,QAArB,CAAJ,CAA9B,CADP;AAEA,IAAA,IAAI,CAAC,CAAC,KAAD,CAAD,CAAJ;AACA,WAAO,KAAP;AACD,GARD;;AAUA,MAAM,MAAM,GAAqB;AAAC,IAAA,MAAM,EAAE;AAAT,GAAjC;AACA,MAAM,KAAK,GAAoB;AAAC,IAAA,IAAI,EAAJ;AAAD,GAA/B;AAEA,SAAO,MAAM,CAAC,aAAP,CACI,OADJ,EACa,MADb,EAC6C;AAAK;AADlD,IAEI,UAFJ,EAEgB,KAFhB,CAAP;AAGD;;AAED,OAAO,IAAM,UAAU,GAAG,EAAE,CAAC;AAAC,EAAA,WAAW,EAAX;AAAD,CAAD,CAArB","sourceRoot":"","sourcesContent":["/**\r\n * @license\r\n * Copyright 2020 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport { ENGINE } from '../engine';\r\nimport { LogSoftmax } from '../kernel_names';\r\nimport { convertToTensor } from '../tensor_util_env';\r\nimport { cast } from './cast';\r\nimport { exp } from './exp';\r\nimport { log } from './log';\r\nimport { max } from './max';\r\nimport { op } from './operation';\r\nimport { sub } from './sub';\r\nimport { sum } from './sum';\r\n/**\r\n * Computes the log softmax.\r\n *\r\n * ```js\r\n * const a = tf.tensor1d([1, 2, 3]);\r\n *\r\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\r\n * ```\r\n *\r\n * ```js\r\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\r\n *\r\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\r\n * ```\r\n *\r\n * @param logits The logits array.\r\n * @param axis The dimension softmax would be performed on. Defaults to `-1`\r\n *     which indicates the last dimension.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Normalization'}\r\n */\r\nfunction logSoftmax_(logits, axis = -1) {\r\n    const $logits = convertToTensor(logits, 'logits', 'logSoftmax');\r\n    if (axis === -1) {\r\n        axis = $logits.rank - 1;\r\n    }\r\n    if (axis !== $logits.rank - 1) {\r\n        throw Error('Log Softmax along a non-last dimension is not yet supported. ' +\r\n            `Logits was rank ${$logits.rank} and axis was ${axis}`);\r\n    }\r\n    const forward = (backend, save) => {\r\n        const keepDims = true;\r\n        const xMax = max(logits, axis, true);\r\n        const shifted = sub(logits, xMax);\r\n        const value = sub(cast(shifted, 'float32'), log(sum(exp(shifted), axis, keepDims)));\r\n        save([value]);\r\n        return value;\r\n    };\r\n    const inputs = { logits: $logits };\r\n    const attrs = { axis };\r\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, LogSoftmax, attrs);\r\n}\r\nexport const logSoftmax = op({ logSoftmax_ });\r\n//# sourceMappingURL=log_softmax.js.map"]},"metadata":{},"sourceType":"module"}